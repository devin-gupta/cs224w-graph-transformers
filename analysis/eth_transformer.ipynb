{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8d47c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Dataset shape: (36182, 8)\n",
      "Columns: ['hash', 'block_number', 'from_address', 'to_address', 'value', 'transaction_day', 'root_node', 'logic_path_taken']\n",
      " num nodes: 4480 and num edges: 36182\n"
     ]
    }
   ],
   "source": [
    "# Ethereum Transaction Graph Analysis\n",
    "# Load required libraries\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Load the Ethereum transaction data\n",
    "df = pd.read_csv('ethereum_medium2.csv')\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "print(f\" num nodes: {len(df['from_address'].unique())} and num edges: {len(df)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "defe746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted data: 36182 transactions\n",
      "Date range: 2025-11-06 00:00:00 to 2025-12-04 00:00:00\n",
      "\n",
      "Processed addresses:\n",
      "  Total unique original addresses: 20574\n",
      "  Unique processed addresses (including 'unknown'): 4959\n",
      "  Number of 'unknown' replacements: 20560\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Preprocess data - sort chronologically and handle unseen nodes\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.nn import TransformerConv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Sort by transaction_day and block_number for chronological ordering\n",
    "df['transaction_day'] = pd.to_datetime(df['transaction_day'])\n",
    "df = df.sort_values(['transaction_day', 'block_number']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Sorted data: {len(df)} transactions\")\n",
    "print(f\"Date range: {df['transaction_day'].min()} to {df['transaction_day'].max()}\")\n",
    "\n",
    "# Track seen nodes and replace unseen nodes with 'unknown'\n",
    "seen_nodes = set()\n",
    "UNKNOWN_NODE = 'unknown'\n",
    "\n",
    "# Create new columns for processed addresses\n",
    "df['from_processed'] = df['from_address'].copy()\n",
    "df['to_processed'] = df['to_address'].copy()\n",
    "\n",
    "# Process each transaction chronologically\n",
    "for idx, row in df.iterrows():\n",
    "    from_addr = row['from_address']\n",
    "    to_addr = row['to_address']\n",
    "    \n",
    "    # Replace unseen nodes with 'unknown'\n",
    "    if from_addr not in seen_nodes:\n",
    "        df.at[idx, 'from_processed'] = UNKNOWN_NODE\n",
    "        seen_nodes.add(from_addr)  # Mark as seen after processing\n",
    "    \n",
    "    if to_addr not in seen_nodes:\n",
    "        df.at[idx, 'to_processed'] = UNKNOWN_NODE\n",
    "        seen_nodes.add(to_addr)  # Mark as seen after processing\n",
    "    \n",
    "    # Mark both as seen for future transactions\n",
    "    seen_nodes.add(from_addr)\n",
    "    seen_nodes.add(to_addr)\n",
    "\n",
    "print(f\"\\nProcessed addresses:\")\n",
    "print(f\"  Total unique original addresses: {len(set(df['from_address'].unique()) | set(df['to_address'].unique()))}\")\n",
    "print(f\"  Unique processed addresses (including 'unknown'): {len(set(df['from_processed'].unique()) | set(df['to_processed'].unique()))}\")\n",
    "print(f\"  Number of 'unknown' replacements: {sum((df['from_processed'] == UNKNOWN_NODE) | (df['to_processed'] == UNKNOWN_NODE))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42a2a33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge attribute normalization: mean=9.72e+18, std=2.78e+20\n",
      "\n",
      "Testing graph snapshot building...\n",
      "  Snapshot with 100 transactions: 100 edges, 19 nodes\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build temporal graph snapshots incrementally\n",
    "# Normalize edge attributes (transaction values)\n",
    "value_mean = df['value'].astype(float).mean()\n",
    "value_std = df['value'].astype(float).std()\n",
    "print(f\"Edge attribute normalization: mean={value_mean:.2e}, std={value_std:.2e}\")\n",
    "\n",
    "def build_graph_snapshot(transactions_up_to_idx, node_to_idx):\n",
    "    \"\"\"\n",
    "    Build a graph snapshot from transactions up to a given index.\n",
    "    Returns edge_index and edge_attr tensors.\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    edge_attrs = []\n",
    "    \n",
    "    for idx in range(transactions_up_to_idx):\n",
    "        row = df.iloc[idx]\n",
    "        from_node = row['from_processed']\n",
    "        to_node = row['to_processed']\n",
    "        \n",
    "        # Get node indices\n",
    "        if from_node not in node_to_idx:\n",
    "            node_to_idx[from_node] = len(node_to_idx)\n",
    "        if to_node not in node_to_idx:\n",
    "            node_to_idx[to_node] = len(node_to_idx)\n",
    "        \n",
    "        from_idx = node_to_idx[from_node]\n",
    "        to_idx = node_to_idx[to_node]\n",
    "        \n",
    "        edges.append([from_idx, to_idx])\n",
    "        \n",
    "        # Use transaction value as edge attribute (normalized)\n",
    "        value = float(row['value'])\n",
    "        normalized_value = (value - value_mean) / (value_std + 1e-8)\n",
    "        edge_attrs.append([normalized_value])\n",
    "    \n",
    "    if len(edges) == 0:\n",
    "        return None, None, node_to_idx\n",
    "    \n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attrs, dtype=torch.float)\n",
    "    \n",
    "    return edge_index, edge_attr, node_to_idx\n",
    "\n",
    "# Test the function\n",
    "print(\"\\nTesting graph snapshot building...\")\n",
    "test_node_to_idx = {}\n",
    "test_edge_index, test_edge_attr, test_node_to_idx = build_graph_snapshot(100, test_node_to_idx)\n",
    "if test_edge_index is not None:\n",
    "    print(f\"  Snapshot with 100 transactions: {test_edge_index.shape[1]} edges, {len(test_node_to_idx)} nodes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "faa59326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Transformer model defined\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Define Graph Transformer Model\n",
    "class GraphTransformerLinkPredictor(nn.Module):\n",
    "    def __init__(self, num_nodes, hidden_dim=128, num_heads=4, num_layers=2, edge_dim=1):\n",
    "        super(GraphTransformerLinkPredictor, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Node embedding layer\n",
    "        self.node_embedding = nn.Embedding(num_nodes, hidden_dim)\n",
    "        \n",
    "        # Graph Transformer layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(TransformerConv(\n",
    "            hidden_dim, hidden_dim, heads=num_heads, \n",
    "            edge_dim=edge_dim, dropout=0.1, concat=True\n",
    "        ))\n",
    "        \n",
    "        # If multiple layers, need to adjust dimensions\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(TransformerConv(\n",
    "                hidden_dim * num_heads, hidden_dim, heads=num_heads,\n",
    "                edge_dim=edge_dim, dropout=0.1, concat=True\n",
    "            ))\n",
    "        \n",
    "        # Final layer to get node embeddings\n",
    "        self.final_conv = TransformerConv(\n",
    "            hidden_dim * num_heads, hidden_dim, heads=1,\n",
    "            edge_dim=edge_dim, dropout=0.1, concat=False\n",
    "        )\n",
    "        \n",
    "        # Link prediction head\n",
    "        self.link_predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, node_indices, edge_index, edge_attr):\n",
    "        \"\"\"\n",
    "        Forward pass for link prediction.\n",
    "        node_indices: tensor of node indices to get embeddings for\n",
    "        edge_index: graph edge indices\n",
    "        edge_attr: edge attributes\n",
    "        \"\"\"\n",
    "        # Get node embeddings\n",
    "        x = self.node_embedding(node_indices)\n",
    "        \n",
    "        # Apply graph transformer layers\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            x = F.relu(x)\n",
    "        \n",
    "        # Final layer\n",
    "        x = self.final_conv(x, edge_index, edge_attr)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def predict_link(self, source_emb, target_emb):\n",
    "        \"\"\"Predict probability of link between source and target embeddings.\"\"\"\n",
    "        # Concatenate source and target embeddings\n",
    "        pair_emb = torch.cat([source_emb, target_emb], dim=-1)\n",
    "        # Get logit\n",
    "        logit = self.link_predictor(pair_emb)\n",
    "        # Return probability\n",
    "        return torch.sigmoid(logit)\n",
    "\n",
    "# Initialize model (will set num_nodes after processing data)\n",
    "print(\"Graph Transformer model defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3768bb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal split:\n",
      "  Training: 28945 transactions (2025-11-06 00:00:00 to 2025-12-04 00:00:00)\n",
      "  Validation: 7237 transactions (2025-12-04 00:00:00 to 2025-12-04 00:00:00)\n",
      "\n",
      "Node mapping from training data:\n",
      "  Total nodes: 4015\n",
      "  Includes 'unknown': True\n",
      "\n",
      "Using device: cpu\n",
      "  Maximum nodes (for embedding table): 4959\n",
      "\n",
      "Model initialized:\n",
      "  Parameters: 2,246,401\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Create temporal train/validation split\n",
    "# Use first 80% of transactions for training, last 20% for validation\n",
    "split_idx = int(len(df) * 0.8)\n",
    "train_df = df.iloc[:split_idx].copy()\n",
    "val_df = df.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"Temporal split:\")\n",
    "print(f\"  Training: {len(train_df)} transactions ({train_df['transaction_day'].min()} to {train_df['transaction_day'].max()})\")\n",
    "print(f\"  Validation: {len(val_df)} transactions ({val_df['transaction_day'].min()} to {val_df['transaction_day'].max()})\")\n",
    "\n",
    "# Build node mapping from training data only\n",
    "train_node_to_idx = {}\n",
    "train_edge_index, train_edge_attr, train_node_to_idx = build_graph_snapshot(len(train_df), train_node_to_idx)\n",
    "\n",
    "print(f\"\\nNode mapping from training data:\")\n",
    "print(f\"  Total nodes: {len(train_node_to_idx)}\")\n",
    "print(f\"  Includes 'unknown': {UNKNOWN_NODE in train_node_to_idx}\")\n",
    "\n",
    "# Initialize model with correct number of nodes\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "# We'll need to handle dynamic node addition, so we'll use a larger embedding table\n",
    "# Estimate max nodes (all unique nodes in dataset)\n",
    "max_nodes = len(set(df['from_processed'].unique()) | set(df['to_processed'].unique()))\n",
    "print(f\"  Maximum nodes (for embedding table): {max_nodes}\")\n",
    "\n",
    "model = GraphTransformerLinkPredictor(\n",
    "    num_nodes=max_nodes,\n",
    "    hidden_dim=128,\n",
    "    num_heads=4,\n",
    "    num_layers=2,\n",
    "    edge_dim=1\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\nModel initialized:\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b8da821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing training pair creation...\n",
      "  Created 2 pairs for transaction 100: 1 positive, 1 negative\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create training pairs with positive and negative samples\n",
    "def create_training_pairs(transaction_idx, node_to_idx, snapshot_node_to_idx=None, negative_ratio=1):\n",
    "    \"\"\"\n",
    "    Create positive and negative training pairs for a transaction.\n",
    "    Returns list of (source_node, target_node, label) tuples (using node names, not indices).\n",
    "    If snapshot_node_to_idx is provided, only uses nodes in the snapshot for negatives.\n",
    "    \"\"\"\n",
    "    row = df.iloc[transaction_idx]\n",
    "    source = row['from_processed']\n",
    "    actual_target = row['to_processed']\n",
    "    \n",
    "    # Ensure nodes are in node_to_idx\n",
    "    if source not in node_to_idx:\n",
    "        node_to_idx[source] = len(node_to_idx)\n",
    "    if actual_target not in node_to_idx:\n",
    "        node_to_idx[actual_target] = len(node_to_idx)\n",
    "    \n",
    "    # Positive sample (using node names)\n",
    "    pairs = [(source, actual_target, 1)]\n",
    "    \n",
    "    # Negative samples: sample random nodes that are NOT connected to source\n",
    "    # Use snapshot nodes if provided, otherwise all nodes\n",
    "    if snapshot_node_to_idx is not None:\n",
    "        candidate_nodes = set(snapshot_node_to_idx.keys())\n",
    "    else:\n",
    "        candidate_nodes = set(node_to_idx.keys())\n",
    "    \n",
    "    # Get nodes already connected to source (in current snapshot)\n",
    "    connected_nodes = set()\n",
    "    for idx in range(transaction_idx):\n",
    "        prev_row = df.iloc[idx]\n",
    "        if prev_row['from_processed'] == source:\n",
    "            target = prev_row['to_processed']\n",
    "            connected_nodes.add(target)\n",
    "    \n",
    "    # Sample negative targets (nodes not connected to source)\n",
    "    available_negatives = list(candidate_nodes - connected_nodes - {source})\n",
    "    \n",
    "    # If we don't have enough negatives, we can use any node except source\n",
    "    if len(available_negatives) == 0:\n",
    "        available_negatives = list(candidate_nodes - {source})\n",
    "    \n",
    "    # Sample negative examples\n",
    "    num_negatives = negative_ratio\n",
    "    if len(available_negatives) > 0:\n",
    "        negative_targets = np.random.choice(\n",
    "            available_negatives, \n",
    "            size=min(num_negatives, len(available_negatives)), \n",
    "            replace=False\n",
    "        )\n",
    "        for neg_target in negative_targets:\n",
    "            pairs.append((source, neg_target, 0))\n",
    "    \n",
    "    return pairs, node_to_idx\n",
    "\n",
    "# Test the function\n",
    "print(\"Testing training pair creation...\")\n",
    "test_node_to_idx = {}\n",
    "# Build snapshot up to index 100\n",
    "test_edge_index, _, test_node_to_idx = build_graph_snapshot(100, test_node_to_idx)\n",
    "# Create pairs for transaction at index 100\n",
    "test_pairs, test_node_to_idx = create_training_pairs(100, test_node_to_idx, snapshot_node_to_idx=test_node_to_idx, negative_ratio=1)\n",
    "print(f\"  Created {len(test_pairs)} pairs for transaction 100: {sum(1 for _, _, label in test_pairs if label == 1)} positive, {sum(1 for _, _, label in test_pairs if label == 0)} negative\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9715c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:  23%|██▎       | 105/453 [06:10<39:48,  6.86s/it]"
     ]
    }
   ],
   "source": [
    "# Step 6: Training loop with temporal constraints\n",
    "def train_epoch(model, optimizer, train_df, node_to_idx, device, batch_size=32, negative_ratio=1):\n",
    "    \"\"\"Train for one epoch, processing transactions chronologically.\"\"\"\n",
    "    model.train()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    all_losses = []\n",
    "    current_node_to_idx = node_to_idx.copy()\n",
    "    \n",
    "    # Process transactions in batches\n",
    "    num_batches = (len(train_df) + batch_size - 1) // batch_size\n",
    "    \n",
    "    for batch_idx in tqdm(range(num_batches), desc=\"Training batches\"):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(train_df))\n",
    "        \n",
    "        # Build graph snapshot up to current batch start\n",
    "        snapshot_end = start_idx\n",
    "        edge_index, edge_attr, snapshot_node_to_idx = build_graph_snapshot(\n",
    "            snapshot_end, current_node_to_idx.copy()\n",
    "        )\n",
    "        \n",
    "        if edge_index is None or edge_index.shape[1] == 0:\n",
    "            # Still need to update node_to_idx for pairs creation\n",
    "            for trans_idx in range(start_idx, end_idx):\n",
    "                _, current_node_to_idx = create_training_pairs(\n",
    "                    trans_idx, current_node_to_idx, negative_ratio=negative_ratio\n",
    "                )\n",
    "            continue\n",
    "        \n",
    "        # Move to device\n",
    "        edge_index = edge_index.to(device)\n",
    "        edge_attr = edge_attr.to(device)\n",
    "        \n",
    "        # Get all node indices in current snapshot\n",
    "        num_nodes_in_snapshot = len(snapshot_node_to_idx)\n",
    "        all_node_indices = torch.tensor(list(range(num_nodes_in_snapshot)), dtype=torch.long).to(device)\n",
    "        \n",
    "        # Get node embeddings for all nodes in snapshot\n",
    "        node_embeddings = model(all_node_indices, edge_index, edge_attr)\n",
    "        \n",
    "        # Create training pairs for this batch\n",
    "        batch_pairs = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for trans_idx in range(start_idx, end_idx):\n",
    "            pairs, current_node_to_idx = create_training_pairs(\n",
    "                trans_idx, current_node_to_idx, snapshot_node_to_idx=snapshot_node_to_idx, negative_ratio=negative_ratio\n",
    "            )\n",
    "            \n",
    "            for source_node, target_node, label in pairs:\n",
    "                # Map node names to snapshot indices\n",
    "                if source_node in snapshot_node_to_idx and target_node in snapshot_node_to_idx:\n",
    "                    snapshot_source_idx = snapshot_node_to_idx[source_node]\n",
    "                    snapshot_target_idx = snapshot_node_to_idx[target_node]\n",
    "                    \n",
    "                    if snapshot_source_idx < num_nodes_in_snapshot and snapshot_target_idx < num_nodes_in_snapshot:\n",
    "                        batch_pairs.append((snapshot_source_idx, snapshot_target_idx))\n",
    "                        batch_labels.append(label)\n",
    "        \n",
    "        if len(batch_pairs) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Convert to tensors\n",
    "        source_indices = torch.tensor([p[0] for p in batch_pairs], dtype=torch.long).to(device)\n",
    "        target_indices = torch.tensor([p[1] for p in batch_pairs], dtype=torch.long).to(device)\n",
    "        labels = torch.tensor(batch_labels, dtype=torch.float).to(device)\n",
    "        \n",
    "        # Get embeddings\n",
    "        source_embs = node_embeddings[source_indices]\n",
    "        target_embs = node_embeddings[target_indices]\n",
    "        \n",
    "        # Predict links\n",
    "        pair_embs = torch.cat([source_embs, target_embs], dim=-1)\n",
    "        logits = model.link_predictor(pair_embs).squeeze()\n",
    "        \n",
    "        # Handle single sample case\n",
    "        if logits.dim() == 0:\n",
    "            logits = logits.unsqueeze(0)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        all_losses.append(loss.item())\n",
    "        \n",
    "    return np.mean(all_losses), current_node_to_idx\n",
    "\n",
    "# Initialize optimizer once\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train for a few epochs to test\n",
    "print(\"Starting training...\")\n",
    "train_losses = []\n",
    "for epoch in range(3):\n",
    "    print(f\"\\nEpoch {epoch + 1}/3\")\n",
    "    loss, updated_node_to_idx = train_epoch(\n",
    "        model, optimizer, train_df, train_node_to_idx, device, batch_size=64, negative_ratio=1\n",
    "    )\n",
    "    train_losses.append(loss)\n",
    "    train_node_to_idx = updated_node_to_idx\n",
    "    print(f\"  Average loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aea56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Evaluation on validation set\n",
    "def evaluate(model, val_df, train_node_to_idx, device, batch_size=32, negative_ratio=1):\n",
    "    \"\"\"Evaluate model on validation set.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Start with node mapping from training\n",
    "    current_node_to_idx = train_node_to_idx.copy()\n",
    "    \n",
    "    # Build initial graph snapshot from all training data\n",
    "    train_end = len(train_df)\n",
    "    edge_index, edge_attr, snapshot_node_to_idx = build_graph_snapshot(\n",
    "        train_end, current_node_to_idx.copy()\n",
    "    )\n",
    "    \n",
    "    if edge_index is None:\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    edge_index = edge_index.to(device)\n",
    "    edge_attr = edge_attr.to(device)\n",
    "    \n",
    "    # Process validation transactions\n",
    "    num_batches = (len(val_df) + batch_size - 1) // batch_size\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx in tqdm(range(num_batches), desc=\"Validation batches\"):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = min((batch_idx + 1) * batch_size, len(val_df))\n",
    "            \n",
    "            # Rebuild snapshot up to this validation batch (including all training + previous validation)\n",
    "            snapshot_end = train_end + start_idx\n",
    "            edge_index, edge_attr, snapshot_node_to_idx = build_graph_snapshot(\n",
    "                snapshot_end, current_node_to_idx.copy()\n",
    "            )\n",
    "            \n",
    "            if edge_index is None or edge_index.shape[1] == 0:\n",
    "                # Still update node_to_idx\n",
    "                for trans_idx in range(start_idx, end_idx):\n",
    "                    orig_idx = train_end + trans_idx\n",
    "                    _, current_node_to_idx = create_training_pairs(\n",
    "                        orig_idx, current_node_to_idx, negative_ratio=negative_ratio\n",
    "                    )\n",
    "                continue\n",
    "            \n",
    "            edge_index = edge_index.to(device)\n",
    "            edge_attr = edge_attr.to(device)\n",
    "            \n",
    "            # Get all node indices in current snapshot\n",
    "            num_nodes_in_snapshot = len(snapshot_node_to_idx)\n",
    "            all_node_indices = torch.tensor(\n",
    "                list(range(num_nodes_in_snapshot)), dtype=torch.long\n",
    "            ).to(device)\n",
    "            \n",
    "            # Get node embeddings\n",
    "            node_embeddings = model(all_node_indices, edge_index, edge_attr)\n",
    "            \n",
    "            # Create evaluation pairs\n",
    "            batch_pairs = []\n",
    "            batch_labels = []\n",
    "            \n",
    "            for trans_idx in range(start_idx, end_idx):\n",
    "                # Map to original dataframe index\n",
    "                orig_idx = train_end + trans_idx\n",
    "                pairs, current_node_to_idx = create_training_pairs(\n",
    "                    orig_idx, current_node_to_idx, snapshot_node_to_idx=snapshot_node_to_idx, negative_ratio=negative_ratio\n",
    "                )\n",
    "                \n",
    "                for source_node, target_node, label in pairs:\n",
    "                    # Map node names to snapshot indices\n",
    "                    if source_node in snapshot_node_to_idx and target_node in snapshot_node_to_idx:\n",
    "                        snapshot_source_idx = snapshot_node_to_idx[source_node]\n",
    "                        snapshot_target_idx = snapshot_node_to_idx[target_node]\n",
    "                        \n",
    "                        if snapshot_source_idx < num_nodes_in_snapshot and snapshot_target_idx < num_nodes_in_snapshot:\n",
    "                            batch_pairs.append((snapshot_source_idx, snapshot_target_idx))\n",
    "                            batch_labels.append(label)\n",
    "            \n",
    "            if len(batch_pairs) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Convert to tensors\n",
    "            source_indices = torch.tensor([p[0] for p in batch_pairs], dtype=torch.long).to(device)\n",
    "            target_indices = torch.tensor([p[1] for p in batch_pairs], dtype=torch.long).to(device)\n",
    "            labels = torch.tensor(batch_labels, dtype=torch.float).to(device)\n",
    "            \n",
    "            # Get embeddings and predict\n",
    "            source_embs = node_embeddings[source_indices]\n",
    "            target_embs = node_embeddings[target_indices]\n",
    "            \n",
    "            pair_embs = torch.cat([source_embs, target_embs], dim=-1)\n",
    "            logits = model.link_predictor(pair_embs).squeeze()\n",
    "            \n",
    "            # Handle single sample case\n",
    "            if logits.dim() == 0:\n",
    "                logits = logits.unsqueeze(0)\n",
    "            \n",
    "            probs = torch.sigmoid(logits)\n",
    "            \n",
    "            all_predictions.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Compute metrics\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    if len(all_predictions) == 0:\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    # Binary predictions (threshold at 0.5)\n",
    "    binary_preds = (all_predictions >= 0.5).astype(int)\n",
    "    accuracy = accuracy_score(all_labels, binary_preds)\n",
    "    \n",
    "    # AUC-ROC\n",
    "    if len(np.unique(all_labels)) > 1:\n",
    "        auc = roc_auc_score(all_labels, all_predictions)\n",
    "    else:\n",
    "        auc = 0.0\n",
    "    \n",
    "    return accuracy, auc\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "val_accuracy, val_auc = evaluate(model, val_df, train_node_to_idx, device, batch_size=64, negative_ratio=1)\n",
    "print(f\"\\nValidation Results:\")\n",
    "print(f\"  Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"  AUC-ROC: {val_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d92df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of training progress\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss', marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Training Statistics:\")\n",
    "print(f\"  Initial loss: {train_losses[0]:.4f}\")\n",
    "print(f\"  Final loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"  Improvement: {((train_losses[0] - train_losses[-1]) / train_losses[0] * 100):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2da4d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
